{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install GFPGAN"
      ],
      "metadata": {
        "id": "Z-6u28dB8yBn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Lj2i1e4d8ljt"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/GFPGAN\n",
        "%cd /content/\n",
        "# end\n",
        "import os\n",
        "base_path=os.getcwd()+\"/\"\n",
        "!git clone https://github.com/TencentARC/GFPGAN.git\n",
        "os.chdir(f\"{base_path}GFPGAN\")\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop\n",
        "!pip install realesrgan\n",
        "!pip install gradio\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Models from Public Links"
      ],
      "metadata": {
        "id": "oR-TIEAV9H2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import sys\n",
        "import shutil\n",
        "def fix():\n",
        "  url = \"https://raw.githubusercontent.com/NeuralFalconYT/GFPGAN-video-upscale/main/degradations.py\"\n",
        "  filename = \"/content/degradations.py\"\n",
        "  full_version = sys.version.split(' ')[0]\n",
        "  major_minor_version = '.'.join(full_version.split('.')[:2])\n",
        "  basicsr_path=f\"/usr/local/lib/python{major_minor_version}/dist-packages/basicsr/data/degradations.py\"\n",
        "  # Send a GET request to the URL\n",
        "  response = requests.get(url)\n",
        "  # Check if the request was successful (status code 200)\n",
        "  if response.status_code == 200:\n",
        "      # Write the content to a file\n",
        "      with open(filename, 'wb') as file:\n",
        "          file.write(response.content)\n",
        "      try:\n",
        "        shutil.copy(\"/content/degradations.py\",basicsr_path)\n",
        "        print(f\"Copied to {basicsr_path}\")\n",
        "      except:\n",
        "        print(\"Update the 'basicsr_path' variable -- replace '{major_minor_version}' with the current Python version in Google Colab, such as 3.10.\")\n",
        "\n",
        "  else:\n",
        "      print(\"Failed to download the file.\")\n",
        "fix()\n",
        "\n",
        "\n",
        "base_path=\"/content\"\n",
        "import os\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "from tqdm import tqdm\n",
        "import urllib\n",
        "def conditional_download(url, download_file_path):\n",
        "    print(f\"Downloading {os.path.basename(download_file_path)}\")\n",
        "    base_path = os.path.dirname(download_file_path)\n",
        "\n",
        "    if not os.path.exists(base_path):\n",
        "        os.makedirs(base_path)\n",
        "\n",
        "    if os.path.exists(download_file_path):\n",
        "        os.remove(download_file_path)\n",
        "\n",
        "    try:\n",
        "        request = urllib.request.urlopen(url)  # type: ignore[attr-defined]\n",
        "        total = int(request.headers.get('Content-Length', 0))\n",
        "    except urllib.error.URLError as e:\n",
        "        print(f\"Error: Unable to open the URL - {url}\")\n",
        "        print(f\"Reason: {e.reason}\")\n",
        "        return\n",
        "\n",
        "    with tqdm(total=total, desc='Downloading', unit='B', unit_scale=True, unit_divisor=1024) as progress:\n",
        "        try:\n",
        "            urllib.request.urlretrieve(url, download_file_path, reporthook=lambda count, block_size, total_size: progress.update(block_size))  # type: ignore[attr-defined]\n",
        "        except urllib.error.URLError as e:\n",
        "            print(f\"Error: Failed to download the file from the URL - {url}\")\n",
        "            print(f\"Reason: {e.reason}\")\n",
        "            return\n",
        "\n",
        "    print(f\"Download successful!\")\n",
        "    print(f\"URL: {url}\")\n",
        "    print(f\"Save at: {download_file_path}\")\n",
        "def extract_zip(zip_file_path,extract_path):\n",
        "    # Create the extraction directory if it doesn't exist\n",
        "    os.makedirs(extract_path, exist_ok=True)\n",
        "    # Open the ZIP file\n",
        "    with ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        # Extract all contents to the specified directory\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\"Contents of '{zip_file_path}' extracted to '{extract_path}'.\")\n",
        "\n",
        "\n",
        "inference_gfpgan='https://raw.githubusercontent.com/NeuralFalconYT/GFPGAN-video-upscale/refs/heads/main/inference_gfpgan.py'# @param {type: \"string\"}\n",
        "conditional_download(inference_gfpgan,f\"{base_path}/GFPGAN/inference_gfpgan.py\")\n",
        "# download_image='https://raw.githubusercontent.com/neuralfalcon/GFPGAN-video-upscale/main/Download.png'# @param {type: \"string\"}\n",
        "# conditional_download(download_image,f\"{base_path}/GFPGAN/Download.png\")\n",
        "gfpgan_model = 'https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth '  # @param {type: \"string\"}\n",
        "if not os.path.exists(f\"{base_path}/GFPGAN/experiments/pretrained_models/GFPGANv1.3.pth\"):\n",
        "  conditional_download(gfpgan_model,f\"{base_path}/GFPGAN/experiments/pretrained_models/GFPGANv1.3.pth\")\n",
        "RealESRGAN = 'https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth'  # @param {type: \"string\"}\n",
        "if not os.path.exists(f\"{base_path}/GFPGAN/gfpgan/weights/RealESRGAN_x2plus.pth\"):\n",
        "  conditional_download(RealESRGAN,f\"{base_path}/GFPGAN/gfpgan/weights/RealESRGAN_x2plus.pth\")\n",
        "detection_Resnet50 = 'https://github.com/xinntao/facexlib/releases/download/v0.1.0/detection_Resnet50_Final.pth'  # @param {type: \"string\"}\n",
        "if not os.path.exists(f\"{base_path}/GFPGAN/gfpgan/weights/detection_Resnet50_Final.pth\"):\n",
        "  conditional_download(detection_Resnet50,f\"{base_path}/GFPGAN/gfpgan/weights/detection_Resnet50_Final.pth\")\n",
        "parsing_parsenet = 'https://github.com/xinntao/facexlib/releases/download/v0.2.2/parsing_parsenet.pth'  # @param {type: \"string\"}\n",
        "if not os.path.exists(f\"{base_path}/GFPGAN/gfpgan/weights/parsing_parsenet.pth\"):\n",
        "  conditional_download(parsing_parsenet,f\"{base_path}/GFPGAN/gfpgan/weights/parsing_parsenet.pth\")\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "BCCKJnNp83C2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "nVNlNPTX9Y-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path=\"/content\"\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from os import path\n",
        "import shutil\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "os.chdir(f\"{base_path}/GFPGAN\")\n",
        "def create_directory(directory_path):\n",
        "    if os.path.exists(directory_path):\n",
        "        shutil.rmtree(directory_path)\n",
        "    os.makedirs(directory_path)\n",
        "\n",
        "def extract_frames(video_path):\n",
        "  directory_path = f\"{base_path}/images\"\n",
        "  create_directory(directory_path)\n",
        "  var=os.system(f\" ffmpeg -i {video_path} {base_path}/images/%06d.jpg\")\n",
        "\n",
        "  if var==0:\n",
        "    print(\"We extracted frames Successfully\")\n",
        "    print(f\"Number of Images {len(os.listdir(directory_path))}\")\n",
        "  else:\n",
        "    print(\"Failed to extract frames\")\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "def generate_random_name(video_filename):\n",
        "    base_name, extension = os.path.splitext(os.path.basename(video_filename))\n",
        "    random_uuid = str(uuid.uuid4().hex)[:6]\n",
        "    if os.path.exists(f\"{base_path}/gdrive/MyDrive/upload/\"):\n",
        "     new_name = f\"{base_path}/gdrive/MyDrive/upload/{base_name}_GFPGAN_{random_uuid}{extension}\"\n",
        "    else:\n",
        "      dir_name=os.path.dirname(video_filename)\n",
        "      if len(dir_name)!=0:\n",
        "        new_name = f\"{dir_name}/{base_name}_GFPGAN_{random_uuid}{extension}\"\n",
        "      else:\n",
        "        new_name = f\"{base_path}/{base_name}_GFPGAN_{random_uuid}{extension}\"\n",
        "\n",
        "    return new_name\n",
        "\n",
        "def make_video():\n",
        "    restoredFramesPath = f'{base_path}/GFPGAN/results/restored_imgs/'\n",
        "    processedVideoOutputPath = f'{base_path}/output'\n",
        "    create_directory(processedVideoOutputPath)\n",
        "    dir_list = os.listdir(restoredFramesPath)\n",
        "    dir_list.sort()\n",
        "\n",
        "    batch = 0\n",
        "    batchSize = 100\n",
        "    # print(dir_list)\n",
        "    for i in range(0, len(dir_list), batchSize):\n",
        "        img_array = []\n",
        "        start, end = i, i + batchSize\n",
        "        print(\"processing \", start, end)\n",
        "        for filename in dir_list[start:end]:\n",
        "            filename = restoredFramesPath + filename\n",
        "            # print(filename)\n",
        "            img = cv2.imread(filename)\n",
        "            if img is None:\n",
        "                continue\n",
        "            height, width, layers = img.shape\n",
        "            size = (width, height)\n",
        "            img_array.append(img)\n",
        "\n",
        "        # Save the video as MP4\n",
        "        temp_video_path=processedVideoOutputPath + f'/{str(batch).zfill(4)}.mp4'\n",
        "        out = cv2.VideoWriter(temp_video_path,\n",
        "                              cv2.VideoWriter_fourcc(*'mp4v'), 25, size)\n",
        "        batch = batch + 1\n",
        "\n",
        "        for i in range(len(img_array)):\n",
        "            out.write(img_array[i])\n",
        "        out.release()\n",
        "        if os.path.exists(f\"{base_path}/gdrive/MyDrive/upload/\"):\n",
        "          temp_drive_video_path=f\"{base_path}/gdrive/MyDrive/upload\" + f'/{str(batch).zfill(4)}.mp4'\n",
        "          # shutil.copy(temp_video_path,temp_drive_video_path)\n",
        "\n",
        "\n",
        "\n",
        "def update_join():\n",
        "  video_folder = f'{base_path}/output'\n",
        "  output_txt_file = f'{base_path}/join.txt'\n",
        "  video_files = [file for file in os.listdir(video_folder) if file.endswith('.mp4')]\n",
        "  video_files.sort()\n",
        "  with open(output_txt_file, 'w') as file:\n",
        "      for video_file in video_files:\n",
        "          file.write(f\"file '{os.path.join(video_folder, video_file)}'\\n\")\n",
        "\n",
        "  print(f\"join.txt file created at: {output_txt_file}\")\n",
        "  return output_txt_file\n",
        "import os\n",
        "import shutil\n",
        "def clean_results():\n",
        "  if os.path.exists(f'{base_path}/GFPGAN/results'):\n",
        "    for i in os.listdir(f\"{base_path}/GFPGAN/results\"):\n",
        "      if os.path.exists(f\"{base_path}/GFPGAN/results/{i}\"):\n",
        "        shutil.rmtree(f\"{base_path}/GFPGAN/results/{i}\")\n",
        "import uuid\n",
        "import os\n",
        "def get_final_video_name():\n",
        "  generated_uuid = str(uuid.uuid4())[:8]\n",
        "  video_name=f\"{base_path}/{generated_uuid}.mp4\"\n",
        "  return video_name\n",
        "\n",
        "def upscale_video(video_path):\n",
        "  extract_frames(video_path)\n",
        "  if os.getcwd()!=f\"{base_path}/GFPGAN\":\n",
        "    os.chdir(f\"{base_path}/GFPGAN\")\n",
        "  clean_results()\n",
        "  var=os.system(f\"python inference_gfpgan.py -i {base_path}/images -o results -v 1.3 -s 2 --bg_upsampler realesrgan\")\n",
        "  if var!=0:\n",
        "    print(\"Image Upscale Failed\")\n",
        "\n",
        "  make_video()\n",
        "  update_join()\n",
        "  var1=os.system(f\"ffmpeg -f concat -safe 0 -i {base_path}/join.txt -c copy {base_path}/upscale.mp4 -y\")\n",
        "  if var1!=0:\n",
        "    print(\"Marged Video Failed\")\n",
        "  if os.path.exists(f\"{base_path}/audio.wav\"):\n",
        "    os.remove(f\"{base_path}/audio.wav\")\n",
        "  var2=os.system(f\"ffmpeg -i {video_path} {base_path}/audio.wav -y\")\n",
        "  if var2!=0:\n",
        "    print(\"ffmpeg Extract audio failed\")\n",
        "  if os.path.exists(f\"{base_path}/final_result.mp4\"):\n",
        "    os.remove(f\"{base_path}/final_result.mp4\")\n",
        "  var3=os.system(f\"ffmpeg -i {base_path}/upscale.mp4 -i {base_path}/audio.wav -c:v copy -map 0:v -map 1:a -y {base_path}/final_result.mp4\")\n",
        "  if var3==0:\n",
        "    print(f\"Video Save at {base_path}/final_result.mp4\")\n",
        "  else:\n",
        "    print(\"ffmpeg video and audio mix failed\")\n",
        "\n",
        "  new_filename = generate_random_name(video_path)\n",
        "  if os.path.exists(f\"{base_path}/final_result.mp4\"):\n",
        "    shutil.copy(f\"{base_path}/final_result.mp4\",new_filename)\n",
        "  else:\n",
        "    shutil.copy(f\"{base_path}/upscale.mp4\",new_filename)\n",
        "  print(f\"GFPGAN Upscale video copy save at {new_filename}\")\n",
        "  return new_filename\n",
        "from google.colab import output\n",
        "def successful():\n",
        "  output.eval_js('new Audio(\"https://www.myinstants.com/media/sounds/anime-wow-sound-effect.mp3\").play()')\n",
        "\n",
        "def error():\n",
        "  output.eval_js('new Audio(\"https://www.myinstants.com/media/sounds/movie_1.mp3\").play()')\n",
        "\n",
        "import re\n",
        "def clean_file_name(file_path):\n",
        "  file_name, file_extension = os.path.splitext(os.path.basename(file_path))\n",
        "  cleaned_file_name = re.sub(r'[^a-zA-Z ]', '', file_name).replace(' ', '_').strip('_')\n",
        "  cleaned_file_name = re.sub(r'_+', '_', cleaned_file_name)\n",
        "  new_file_path =cleaned_file_name + file_extension\n",
        "  return new_file_path\n",
        "def gradio_video_upscale(input_video_path):\n",
        "  clean_file=f\"{base_path}/{clean_file_name(input_video_path)}\"\n",
        "  shutil.copy(input_video_path,clean_file)\n",
        "  save_path=upscale_video(clean_file)\n",
        "  return save_path,save_path,save_path\n",
        "\n",
        "def upscale_image(img_path):\n",
        "  if not os.path.exists(f\"{base_path}/upscaled_image\"):\n",
        "    os.mkdir(f\"{base_path}/upscaled_image\")\n",
        "  if os.getcwd()!=f\"{base_path}/GFPGAN\":\n",
        "    os.chdir(f\"{base_path}/GFPGAN\")\n",
        "  clean_results()\n",
        "  var=os.system(f\"python inference_gfpgan.py -i {img_path} -o results -v 1.3 -s 2 --bg_upsampler realesrgan\")\n",
        "  if var!=0:\n",
        "    print(\"Image Upscale Failed\")\n",
        "    return None\n",
        "  else:\n",
        "    file_name = os.path.basename(img_path)\n",
        "    image_path=f\"{base_path}/GFPGAN/results/restored_imgs/{file_name}\"\n",
        "    new_path=f\"{base_path}/upscaled_image/{file_name}\"\n",
        "    shutil.copy(image_path,new_path)\n",
        "    return new_path\n",
        "\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def zip_folder(folder_path, zip_path):\n",
        "    if os.path.exists(zip_path):\n",
        "      os.remove(zip_path)\n",
        "    with ZipFile(zip_path, 'w') as zipf:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, folder_path)\n",
        "                zipf.write(file_path, arcname=arcname)\n",
        "from PIL import Image\n",
        "\n",
        "def manage_files(multiple_images):\n",
        "  if len(multiple_images)==1:\n",
        "    save_path=upscale_image(multiple_images[-1])\n",
        "    pil_image = Image.open(save_path)\n",
        "    return save_path,save_path,pil_image\n",
        "  else:\n",
        "    random_uuid = str(uuid.uuid4().hex)[:6]\n",
        "    os.makedirs(f\"{base_path}/temp/GFPGAN_{random_uuid}\")\n",
        "    for image in multiple_images:\n",
        "      save_path=upscale_image(image)\n",
        "      file_name=os.path.basename(save_path)\n",
        "      shutil.copy(save_path,f\"{base_path}/temp/GFPGAN_{random_uuid}/{file_name}\")\n",
        "    zip_folder(f\"{base_path}/temp/GFPGAN_{random_uuid}\", f\"{base_path}/temp/GFPGAN_{random_uuid}.zip\")\n",
        "    full_path = os.path.abspath(f\"{base_path}/temp/GFPGAN_{random_uuid}.zip\")\n",
        "    pil_image = Image.open(f\"{base_path}/GFPGAN/Download.png\")\n",
        "    return f\"{base_path}/temp/GFPGAN_{random_uuid}.zip\",full_path,pil_image"
      ],
      "metadata": {
        "id": "38UqTXZ19Ni8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_file_name(file_path):\n",
        "  file_name, file_extension = os.path.splitext(os.path.basename(file_path))\n",
        "  cleaned_file_name = re.sub(r'[^a-zA-Z ]', '', file_name).replace(' ', '_').strip('_')\n",
        "  cleaned_file_name = re.sub(r'_+', '_', cleaned_file_name)\n",
        "  new_file_path =cleaned_file_name + file_extension\n",
        "  return new_file_path\n",
        "\n",
        "input_video_path = '/content/test_video1.mp4'\n",
        "clean_file=f\"{base_path}/{clean_file_name(input_video_path)}\"\n",
        "shutil.copy(input_video_path,clean_file)\n",
        "save_path=upscale_video(clean_file)\n",
        "successful()\n",
        "from google.colab import files\n",
        "files.download(save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "OPv2Y9Cj9bDl",
        "outputId": "007ff54e-c949-45ce-8111-2f564cd77c4c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We extracted frames Successfully\n",
            "Number of Images 80\n",
            "processing  0 100\n",
            "join.txt file created at: /content/join.txt\n",
            "Video Save at /content/final_result.mp4\n",
            "GFPGAN Upscale video copy save at /content/testvideo_GFPGAN_8428e9.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_10e86a11-554c-4a15-a6e2-20f06e370eb3\", \"testvideo_GFPGAN_8428e9.mp4\", 949207)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oxs1sT7x9mCR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}